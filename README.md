# Masters Thesis
## By Caroline Belka, Joshua Chen, Jonas Wallstein
## Advisor: Gabor Lugosi

Absract: This thesis explores the differences between Convolutional Neural Networks
(CNNs) and Vision Transformers (ViTs) to understand how these architectures
perceive and learn from images. We first provide an in-depth explanation and
comparative literature review of CNNs and ViTs. We then investigate how both
models adapt to classifying satellite images and rotated scene images,
evaluated in terms of rotational invariance and learned representations using
Centered Kernel Alignment (CKA). ViTs demonstrated better performance and
stability, which we attribute to their ability to integrate global information through
self-attention mechanisms, while CNNs showed more variation due to their
hierarchical feature learning and local receptive fields.
